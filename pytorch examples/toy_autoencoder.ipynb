{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Autoencoder, MNIST dataset\n",
    "\n",
    "\n",
    "### Some comments:\n",
    "- the 2 downconv + 2 upconv net is easier for training\n",
    "- the 3+3 layers net I coded works well when trained on 20 epochs and a tanh layer as the last one of the decoder (why ReLU doesnt perform as well?)\n",
    "- should try BCE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms \n",
    "from torchvision.utils import save_image\n",
    "import random\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsample_dir = '1st_autoencoder'\\nif not os.path.exists(sample_dir):\\n    os.makedirs(sample_dir)\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\"\"\"\n",
    "sample_dir = '1st_autoencoder'\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)\n",
    "\"\"\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize( mean = (0.5,0.5,0.5), std = (0.5,0.5,0.5))])\n",
    "\n",
    "#dataset for training (download = True to download the dataset for the first time)\n",
    "train_dataset = torchvision.datasets.MNIST('mnist/',train=True,transform=transform, download=False)\n",
    "#loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#dataset for testing (download = True to download the dataset for the first time)\n",
    "test_dataset = torchvision.datasets.MNIST('mnist/',train=False,transform=transform, download=False)\n",
    "#loader\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.enc_1 = nn.Sequential(\n",
    "            nn.Conv2d(1,16, kernel_size = 5, stride = 2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.enc_2 = nn.Sequential(\n",
    "            nn.Conv2d(16,32, kernel_size = 5, stride = 2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.enc_3 = nn.Sequential(\n",
    "            nn.Conv2d(32,64, kernel_size = 3, stride = 2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.dec_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size = 4, stride = 2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.dec_2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size = 5, stride = 2),\n",
    "            nn.ReLU()\n",
    "        )       \n",
    "        \n",
    "        self.dec_3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16, 1, kernel_size = 8, stride = 2),\n",
    "            nn.Tanh()\n",
    "            #nn.ReLU()\n",
    "        )        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.enc_1(x)\n",
    "        out = self.enc_2(out)\n",
    "        out = self.enc_3(out)\n",
    "        \n",
    "        out = self.dec_1(out)\n",
    "        out = self.dec_2(out)\n",
    "        out = self.dec_3(out)\n",
    "        return out        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_autoencoder.py from github repo L1aoXingyu/pytorch-beginner :\n",
    "\"\"\"\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "        nn.Conv2d(1, 16, 3, stride=3, padding=1),  # b, 16, 10, 10\n",
    "        nn.ReLU(True),\n",
    "        nn.MaxPool2d(2, stride=2),  # b, 16, 5, 5\n",
    "        nn.Conv2d(16, 8, 3, stride=2, padding=1),  # b, 8, 3, 3\n",
    "        nn.ReLU(True),\n",
    "        nn.MaxPool2d(2, stride=1)  # b, 8, 2, 2\n",
    "    )\n",
    "        self.decoder = nn.Sequential(\n",
    "        nn.ConvTranspose2d(8, 16, 3, stride=2),  # b, 16, 5, 5\n",
    "        nn.ReLU(True),\n",
    "        nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),  # b, 8, 15, 15\n",
    "        nn.ReLU(True),\n",
    "        nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),  # b, 1, 28, 28\n",
    "        nn.Tanh()\n",
    "    )\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x   \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiation, training and saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.BCEWithLogitsLoss() #instead of BCELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "#denormalize the image\n",
    "def denorm(x):\n",
    "    out = x*0.5 + 0.5\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "#train\n",
    "model.train()\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        #forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, images)\n",
    "        \n",
    "        #backward & optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \"\"\" \n",
    "        if (i+1) % 1 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "        \"\"\"        \n",
    "        \n",
    "torch.save(model.state_dict(), 'toy_autoencoder_tanh_mse.pkl')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading  a model and comparing results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loading\n",
    "model_test = Autoencoder()\n",
    "model_test.load_state_dict(torch.load('toy_autoencoder_tanh_mse.pkl'))\n",
    "\n",
    "#autoencode a random image from the test dataset\n",
    "model_test.eval()\n",
    "test_image = random.choice(test_dataset)\n",
    "test_reconst = model_test((test_image[0].unsqueeze_(0)))\n",
    "\n",
    "#plotting (left = test_image ; right = test_reconst)\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow( test_image[0][0][0])\n",
    "axs[1].imshow( test_reconst[0][0].detach().numpy())\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
