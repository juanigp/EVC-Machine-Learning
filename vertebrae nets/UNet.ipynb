{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments:\n",
    "- Work in progress\n",
    "- To use cuda I need to call .cuda() on every tensor I instantiate during my train() procedure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def var_or_cuda(x):\n",
    "    if torch.cuda.is_available():\n",
    "        x = x.cuda()\n",
    "    return Variable(x)\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, cube_len=64):\n",
    "        \n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        self.cube_len = cube_len\n",
    "        self.code_len = cube_len * 8\n",
    "        \n",
    "        #Contracting path:\n",
    "        \n",
    "        self.enc_1 = nn.Sequential(\n",
    "            nn.Conv3d(1, self.cube_len, kernel_size = 4, stride = 2, padding = 1),\n",
    "            nn.BatchNorm3d(self.cube_len),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        \n",
    "        self.enc_2 = nn.Sequential(\n",
    "            nn.Conv3d(self.cube_len, self.cube_len * 2, kernel_size = 4, stride = 2, padding = 1),\n",
    "            nn.BatchNorm3d(self.cube_len * 2),\n",
    "            nn.ReLU()        \n",
    "        )\n",
    "        \n",
    "        self.enc_3 = nn.Sequential(\n",
    "            nn.Conv3d(self.cube_len * 2, self.cube_len * 4, kernel_size = 4, stride = 2, padding = 1),\n",
    "            nn.BatchNorm3d(self.cube_len * 4),\n",
    "            nn.ReLU()        \n",
    "        ) \n",
    "        \n",
    "        self.enc_4 = nn.Sequential(\n",
    "            nn.Conv3d(self.cube_len * 4, self.code_len, kernel_size = 4, stride = 2, padding = 1),\n",
    "            nn.BatchNorm3d(self.code_len),\n",
    "            nn.ReLU()        \n",
    "        ) \n",
    "        \n",
    "        self.enc_5 = nn.Sequential(\n",
    "            nn.Conv3d(self.code_len, self.code_len, kernel_size = 4, stride = 2, padding = 1),\n",
    "            nn.BatchNorm3d(self.code_len),\n",
    "            nn.ReLU()        \n",
    "        )  \n",
    "        \n",
    "        self.enc_6 = nn.Sequential(\n",
    "            nn.Conv3d(self.code_len, self.code_len, kernel_size = 4, stride = 2, padding = 1),\n",
    "            #cant batch norm when features are 1x1x1\n",
    "            #nn.BatchNorm3d(self.code_len),\n",
    "            nn.ReLU()        \n",
    "        )\n",
    "        \n",
    "        #Expansive path\n",
    "        \n",
    "        self.dec_1 = torch.nn.Sequential(\n",
    "            nn.ConvTranspose3d(self.code_len, self.code_len, kernel_size=4, stride=2, padding = 1),\n",
    "            nn.BatchNorm3d(self.code_len),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        #According to the paper this layer also has dropout\n",
    "        self.dec_2 = torch.nn.Sequential(\n",
    "            nn.ConvTranspose3d(self.code_len, self.code_len * 2, kernel_size=4, stride=2, padding = 1),\n",
    "            nn.BatchNorm3d(self.code_len),\n",
    "            nn.ReLU()\n",
    "        )        \n",
    "        \n",
    "        self.dec_3 = torch.nn.Sequential(\n",
    "            nn.ConvTranspose3d(self.code_len * 2, (self.cube_len * 4) * 2, kernel_size=4, stride=2, padding = 1),\n",
    "            nn.BatchNorm3d((self.cube_len * 4) * 2),\n",
    "            nn.ReLU()\n",
    "        )        \n",
    "        \n",
    "        self.dec_4 = torch.nn.Sequential(\n",
    "            nn.ConvTranspose3d((self.cube_len * 4) * 2, (self.cube_len * 2) * 2, kernel_size=4, stride=2, padding = 1),\n",
    "            nn.BatchNorm3d((self.cube_len * 2) * 2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.dec_5 = torch.nn.Sequential(\n",
    "            nn.ConvTranspose3d((self.cube_len * 2) * 2, self.cube_len * 2, kernel_size=4, stride=2, padding = 1),\n",
    "            nn.BatchNorm3d(self.cube_len * 2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.dec_6 = torch.nn.Sequential(\n",
    "            nn.ConvTranspose3d(self.cube_len * 2, 1, kernel_size=4, stride=2, padding = 1),\n",
    "            nn.BatchNorm3d(1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        #downconvolutions\n",
    "        out = self.enc_1(x)\n",
    "        feature_map_1  = out.clone()\n",
    "        \n",
    "        out = self.enc_2(out)\n",
    "        feature_map_2 = out.clone()\n",
    "\n",
    "        out = self.enc_3(out)\n",
    "        feature_map_3 = out.clone()        \n",
    "        \n",
    "        out = self.enc_4(out)\n",
    "        feature_map_4 = out.clone()\n",
    "        \n",
    "        out = self.enc_5(out)\n",
    "        feature_map_5 = out.clone()\n",
    "         \n",
    "        #code\n",
    "        out = self.enc_6(out)\n",
    "        \n",
    "        #upconvolutions\n",
    "        out = self.dec_1(out)\n",
    "        dec_2_in = torch.cat((out, feature_map_5), 1)\n",
    "        \n",
    "        out = self.dec_2(dec_2_in)\n",
    "        dec_3_in = torch.cat((out, feature_map_4), 1)\n",
    "        \n",
    "        out = self.dec_3(dec_3_in)\n",
    "        dec_4_in = torch.cat((out, feature_map_3), 1)\n",
    "        \n",
    "        out = self.dec_4(dec_4_in)\n",
    "        dec_5_in = torch.cat((out, feature_map_2), 1)\n",
    "        \n",
    "        out = self.dec_5(dec_5_in)\n",
    "        dec_6_in = torch.cat((out, feature_map_1), 1)\n",
    "        \n",
    "        out = self.dec_6(dec_6_in)\n",
    "        \n",
    "        return out \n",
    "        \n",
    "    def train(self):\n",
    "        pass\n",
    "    \n",
    "    def load(self):\n",
    "        pass\n",
    "    \n",
    "    def save(self):\n",
    "        pass\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instantiating the model:\n",
    "\n",
    "model = UNet()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
