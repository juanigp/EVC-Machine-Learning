{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U Net, MNIST dataset\n",
    "\n",
    "\n",
    "### A tweak on the toy autoencoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms \n",
    "from torchvision.utils import save_image\n",
    "import random\n",
    "import math\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 20\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize( mean = (0.5,0.5,0.5), std = (0.5,0.5,0.5))])\n",
    "\n",
    "#dataset for training (download = True to download the dataset for the first time)\n",
    "train_dataset = torchvision.datasets.MNIST('mnist/',train=True,transform=transform, download=False)\n",
    "#loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#dataset for testing (download = True to download the dataset for the first time)\n",
    "test_dataset = torchvision.datasets.MNIST('mnist/',train=False,transform=transform, download=False)\n",
    "#loader\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28\n",
      "12\n",
      "4\n",
      "\n",
      "1\n",
      "\n",
      "4\n",
      "12\n",
      "28\n"
     ]
    }
   ],
   "source": [
    "#calculating the sizes of the feature maps for the contracting and expansive paths \n",
    "\n",
    "def o_downconv(i, k, s, p = 0):\n",
    "    o = math.floor( (i + 2*p - k)/s ) + 1\n",
    "    return o\n",
    "\n",
    "def o_upconv(i, k, s, p = 0):\n",
    "    o = (i-1)*s + k - 2*p\n",
    "    return o\n",
    "\n",
    "\n",
    "i = 28\n",
    "d_16 = o_downconv( i, 5, 2)\n",
    "d_32 = o_downconv( d_16, 5, 2)\n",
    "latent = o_downconv( d_32, 3, 2)\n",
    "\n",
    "print('{}\\n{}\\n{}\\n\\n{}\\n'.format(i, d_16, d_32, latent) )\n",
    "\n",
    "u_32 = o_upconv(latent, 4, 2)\n",
    "u_16 = o_upconv (u_32, 6, 2)\n",
    "o = o_upconv(u_16, 6, 2)\n",
    "\n",
    "print('{}\\n{}\\n{}'.format(u_32, u_16, o) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.enc_1 = nn.Sequential(\n",
    "            nn.Conv2d(1,16, kernel_size = 5, stride = 2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.enc_2 = nn.Sequential(\n",
    "            nn.Conv2d(16,32, kernel_size = 5, stride = 2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.enc_3 = nn.Sequential(\n",
    "            nn.Conv2d(32,64, kernel_size = 3, stride = 2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.dec_1 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size = 4, stride = 2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.dec_2 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32 + 32, 16, kernel_size = 6, stride = 2),\n",
    "            nn.ReLU()\n",
    "        )       \n",
    "        \n",
    "        self.dec_3 = nn.Sequential(\n",
    "            nn.ConvTranspose2d(16 + 16, 1, kernel_size = 6, stride = 2),\n",
    "            nn.Tanh()\n",
    "            #nn.ReLU()\n",
    "        )        \n",
    "\n",
    "    def forward(self, x):\n",
    "        #downconvolutions\n",
    "        out = self.enc_1(x)\n",
    "        down_16 = out.clone()\n",
    "        \n",
    "        out = self.enc_2(out)\n",
    "        down_32 = out.clone()\n",
    "        \n",
    "        #code\n",
    "        out = self.enc_3(out)\n",
    "        \n",
    "        #upconvolutions\n",
    "        out = self.dec_1(out)\n",
    "        up_32_32 = torch.cat((out, down_32), 1)\n",
    "        out = self.dec_2(up_32_32)\n",
    "        up_16_16= torch.cat((out, down_16),1)\n",
    "        out = self.dec_3(up_16_16)\n",
    "        return out        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiation, training and saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet()\n",
    "criterion = nn.MSELoss()\n",
    "#criterion = nn.BCEWithLogitsLoss() #instead of BCELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "\n",
    "#denormalize the image\n",
    "def denorm(x):\n",
    "    out = x*0.5 + 0.5\n",
    "    return out.clamp(0, 1)\n",
    "\n",
    "#train\n",
    "model.train()\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        #forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, images)\n",
    "        \n",
    "        #backward & optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "torch.save(model.state_dict(), 'toy_unet.pkl')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading  a model and comparing results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#loading\n",
    "model_test = UNet()\n",
    "model_test.load_state_dict(torch.load('toy_unet.pkl'))\n",
    "\n",
    "#autoencode a random image from the test dataset\n",
    "model_test.eval()\n",
    "test_image = random.choice(test_dataset)\n",
    "test_reconst = model_test((test_image[0].unsqueeze_(0)))\n",
    "\n",
    "#plotting (left = test_image ; right = test_reconst)\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "axs[0].imshow( test_image[0][0][0])\n",
    "axs[1].imshow( test_reconst[0][0].detach().numpy())\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
